---
title: 对抗评测平台
blocks:
  - titleen: Latest news
    viewMoreen: View more
    updates:
      - titleen: Introducing VisionSafety Platform
        subtitleen: '#Vision'
        contenten: >-
          As the safety of vision models remains a cornerstone of AI research,
          we are proud to launch the VisionSafety Platform. This innovative
          platform is designed to evaluate the safety of vision models through
          the creation of more powerful, transferable adversarial attacks,
          alongside the release of million-scale, real-world adversarial
          datasets. This initiative marks a significant step forward in
          enhancing the security and resilience of vision-based AI systems.
        timeen: 2024 Dec 4 | by Vision Team
        img: /uploads/latestUpdates1.png
      - titleen: >-
          Launching the Multimodal Safety Research Project: Tackling New Risks
          in AI
        subtitleen: '#Multimodal'
        contenten: >-
          The rise of multimodal AI presents significant new risks. In response,
          we are launching the Multimodal Safety Research Project, which aims to
          drive community-led research on securing multimodal AI systems. This
          initiative seeks not only to build safe and secure multimodal models
          but also to develop techniques that prevent these systems from being
          misused or turning harmful.
        timeen: 2024 Dec 17 | by Multimodal Team
        img: /uploads/latestUpdates2.png
      - titleen: Do We Truly Understand Large Language Models?
        subtitleen: '#Language'
        contenten: >-
          As LLMs revolutionize technology, a crucial question emerges: Do we
          really understand how they work? Often described as sophisticated
          next-token predictors, LLMs excel in compressing vast amounts of
          information to generate human-like text. But is this mere pattern
          matching, or is there a deeper intelligence at play? This intriguing
          debate challenges us to explore the true nature of these models. Join
          the conversation and share your insights on LLMs!
        timeen: 2024 Dec 17 | by Language Team
        img: /uploads/latestUpdates3.png
    _template: updates
  - title: Our Mission
    body: >
      OpenTAI is an open-source platform that drives cutting-edge Trustworthy AI
      research and fosters open collaboration to build a secure and equitable AI
      future.
    _template: content
  - titleen: Research
    titlezh: Research
    items:
      - projectName: 系外行星检测
        projectDescription: >-
          Adversarial attacks and defenses.Adversarial attacks and
          defenses.Adversarial attacks and defenses.Adversarial attacks and
          defenses.
        projectReadMore: Learn More >
        link: ''
        projectIcon: /uploads/projectIcon1.png
      - projectName: 系外行星检测11
        projectDescription: >-
          Adversarial attacks and defenses.Adversarial attacks and
          defenses.Adversarial attacks and defenses.Adversarial attacks and
          defenses.
        projectReadMore: Learn More >
        link: ''
        projectIcon: /uploads/projectIcon1.png
      - projectName: 寻找走失儿童
        projectDescription: >-
          Adversarial attacks and defenses.Adversarial attacks and
          defenses.Adversarial attacks and defenses.Adversarial attacks and
          defenses.
        projectReadMore: Learn More >
        link: ''
        projectIcon: /uploads/projectIcon1.png
      - projectName: 帮助盲人识字
        projectDescription: >-
          Adversarial attacks and defenses.Adversarial attacks and
          defenses.Adversarial attacks and defenses.Adversarial attacks and
          defenses.
        projectReadMore: Learn More >
        link: ''
        projectIcon: /uploads/projectIcon1.png
      - projectName: 带你认识ChatGPT
        projectDescription: >-
          Adversarial attacks and defenses.Adversarial attacks and
          defenses.Adversarial attacks and defenses.Adversarial attacks and
          defenses.
        projectReadMore: Learn More >
        link: ''
        projectIcon: /uploads/projectIcon1.png
      - projectName: 情感倾向分析
        projectDescription: >-
          Adversarial attacks and defenses.Adversarial attacks and
          defenses.Adversarial attacks and defenses.Adversarial attacks and
          defenses.
        projectReadMore: Learn More >
        link: ''
        projectIcon: /uploads/projectIcon1.png
      - projectName: 情感倾向分析
        projectDescription: >-
          Adversarial attacks and defenses.Adversarial attacks and
          defenses.Adversarial attacks and defenses.Adversarial attacks and
          defenses.
        projectReadMore: Learn More >
        link: ''
        projectIcon: /uploads/projectIcon1.png
    _template: project
  - titleen: Benchmarks
    titlezh: Benchmarks
    items:
      - benchMarkName: VisionSafety
        description: >-
          This platform provides datasets, algorithms, and tools needed for
          large-scale and transferable adversarial robustness evaluation of
          computer vision models.  Every vision model deserves thorough and
          scalable adversarial evaluations before real-world deployment.
        subTitle: 'An Adversarial Evaluation Platform for Computer Vision Models '
        learnMore: Learn More >
        benchMarksImg: /uploads/eye-acc.png
        tags:
          - tagName: vision
          - tagName: transfer attacks
          - tagName: million-scale
    _template: benchMarks
  - titleen: Datasets
    titlezh: Datasets
    items:
      - datasetsName: CC1M-Adv-C/F
        desc: Two million-scale adversarial image datasets.
        subTitle: Transfer Attack
        datasetsBackground: /uploads/datasets2.png
      - datasetsName: AdvPatch-1K
        desc: 'A adversarial T-shirt dataset of 1,131  images from 20 participants.'
        subTitle: Physical Attack
        datasetsBackground: /uploads/datasets2.png
      - datasetsName: WildDeepfake
        desc: >-
          WildDeepfake is a dataset of 7,314 face sequences from 707 deepfake
          videos.
        subTitle: Deepfake
        datasetsBackground: /uploads/datasets2.png
      - datasetsName: DeepSafe
        desc: A safety dataset of 100K questions used by the DeepSafe benchmark.
        subTitle: LLM
        datasetsBackground: /uploads/datasets2.png
    _template: datasets
  - titleen: Tools
    titlezh: Tools
    items:
      - name: BlackdoorLLM
        description: >-
          A Comprehensive Benchmark for Backdoor Attacks on Large Language
          Models
        learnMore: Learn More >
        img: /uploads/Tools2.png
        tagsImage:
          - img: /uploads/tag1.png
          - img: /uploads/tag2.png
          - img: /uploads/tag3.png
          - img: /uploads/tag4.png
      - name: BlackdoorLLM
        description: A Comprehensive Benchmark for Adversarial Attacks on Vision Models
        learnMore: Learn More >
        img: /uploads/BenchMarks2.png
        tagsImage: []
    _template: tools
  - titleen: Partners
    titlezh: Partners
    items:
      - name: Fudan University
        img: /uploads/partner1.png
      - name: Peking University
        img: /uploads/partner2.png
      - name: Harvard University
        img: /uploads/partner3.png
      - name: Yale University
        img: /uploads/partner4.png
    _template: partners
  - titleen: Contributors
    titlezh: Contributors
    items:
      - name: Joseph Moore
      - name: 张伟
      - name: David Davis
      - name: Mark Thompson
      - name: 周阳
      - name: Joseph Moore
      - name: 张伟
      - name: David Davis
      - name: Mark Thompson
      - name: 周阳
      - name: Joseph Moore
      - name: 张伟
      - name: David Davis
      - name: Mark Thompson
      - name: 周阳
      - name: Joseph Moore
      - name: 张伟
      - name: David Davis
      - name: Mark Thompson
      - name: 周阳
    _template: contributors
---

